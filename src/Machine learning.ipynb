{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "BASE_PATH = \"C:/Users/aguil/OneDrive/Desktop/proyectos javier/Decision-Tree-Project-/models/Excel\"\n",
    "TRAIN_PATHS = [\n",
    "    \"X_train_con_outliers.xlsx\",\n",
    "    \"X_train_sin_outliers.xlsx\",\n",
    "    \"X_train_con_outliers_norm.xlsx\",\n",
    "    \"X_train_sin_outliers_norm.xlsx\",\n",
    "    \"X_train_con_outliers_scal.xlsx\",\n",
    "    \"X_train_sin_outliers_scal.xlsx\"\n",
    "]\n",
    "TRAIN_DATASETS = []\n",
    "for path in TRAIN_PATHS:\n",
    "    TRAIN_DATASETS.append(\n",
    "        # pd.read_excel(BASE_PATH + \"/\" + path)\n",
    "        pd.read_excel(f\"{BASE_PATH}/{path}\")\n",
    "        # pd.read_excel(os.path.join(BASE_PATH, path))\n",
    "    )\n",
    "\n",
    "TEST_PATHS = [\n",
    "    \"X_test_con_outliers.xlsx\",\n",
    "    \"X_test_sin_outliers.xlsx\",\n",
    "    \"X_test_con_outliers_norm.xlsx\",\n",
    "    \"X_test_sin_outliers_norm.xlsx\",\n",
    "    \"X_test_con_outliers_scal.xlsx\",\n",
    "    \"X_test_sin_outliers_scal.xlsx\"\n",
    "]\n",
    "TEST_DATASETS = []\n",
    "for path in TEST_PATHS:\n",
    "    TEST_DATASETS.append(\n",
    "        pd.read_excel(f\"{BASE_PATH}/{path}\")\n",
    "    )\n",
    "\n",
    "y_train = pd.read_excel(f\"{BASE_PATH}/y_train.xlsx\")\n",
    "y_test = pd.read_excel(f\"{BASE_PATH}/y_test.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'train': 1.0, 'test': 0.7142857142857143},\n",
       " {'train': 1.0, 'test': 0.7272727272727273},\n",
       " {'train': 1.0, 'test': 0.7142857142857143},\n",
       " {'train': 1.0, 'test': 0.7272727272727273},\n",
       " {'train': 1.0, 'test': 0.7142857142857143},\n",
       " {'train': 1.0, 'test': 0.7272727272727273}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "results = []\n",
    "for index, dataset in enumerate(TRAIN_DATASETS):\n",
    "    print(index)\n",
    "    model = DecisionTreeClassifier(random_state = 42)\n",
    "    model.fit(dataset, y_train)\n",
    "    y_pred_train = model.predict(dataset)\n",
    "    y_pred_test = model.predict(TEST_DATASETS[index])\n",
    "\n",
    "    results.append(\n",
    "        {\n",
    "            \"train\": accuracy_score(y_train, y_pred_train),\n",
    "            \"test\": accuracy_score(y_test, y_pred_test)\n",
    "        }\n",
    "    )\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 10}\n",
      "Mejor accuracy: 0.7459016393442622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aguil\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:528: FitFailedWarning: \n",
      "450 fits failed out of a total of 1350.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "450 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\aguil\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\aguil\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\aguil\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\aguil\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of DecisionTreeClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\aguil\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.7019992  0.7019992  0.7019992\n",
      " 0.7019992  0.7019992  0.7019992  0.7019992  0.7019992  0.7019992\n",
      " 0.7019992  0.7019992  0.7019992  0.7019992  0.7019992  0.7019992\n",
      " 0.7019992  0.7019992  0.7019992         nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.73618553 0.73455951 0.73938425 0.72311076 0.72966813 0.73938425\n",
      " 0.73453285 0.73453285 0.74590164 0.73618553 0.73455951 0.73938425\n",
      " 0.72311076 0.72966813 0.73938425 0.73453285 0.73453285 0.74590164\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.70358523 0.68408637 0.67755564\n",
      " 0.71831267 0.69389578 0.69380248 0.67430361 0.67430361 0.71330135\n",
      " 0.70358523 0.68408637 0.67755564 0.71831267 0.69389578 0.69380248\n",
      " 0.67430361 0.67430361 0.71330135        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.69052379 0.6678262  0.69872051 0.7247501  0.70851659 0.69874717\n",
      " 0.69556178 0.69556178 0.71167533 0.69052379 0.6678262  0.69872051\n",
      " 0.7247501  0.70851659 0.69874717 0.69556178 0.69556178 0.71167533\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.70035986 0.6678262  0.69872051\n",
      " 0.7247501  0.70363854 0.69874717 0.69556178 0.69556178 0.71167533\n",
      " 0.70035986 0.6678262  0.69872051 0.7247501  0.70363854 0.69874717\n",
      " 0.69556178 0.69556178 0.71167533        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.68405971 0.68405971 0.68405971 0.68405971 0.68405971 0.68405971\n",
      " 0.68405971 0.68405971 0.68405971 0.68405971 0.68405971 0.68405971\n",
      " 0.68405971 0.68405971 0.68405971 0.68405971 0.68405971 0.68405971\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.73614554 0.74262295 0.72315074\n",
      " 0.7377449  0.74587498 0.72802879 0.72801546 0.72801546 0.72801546\n",
      " 0.73614554 0.74262295 0.72315074 0.7377449  0.74587498 0.72802879\n",
      " 0.72801546 0.72801546 0.72801546        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.69377582 0.68888445 0.70194589 0.69870718 0.68887112 0.72962815\n",
      " 0.71817939 0.71817939 0.71015594 0.69377582 0.68888445 0.70194589\n",
      " 0.69870718 0.68887112 0.72962815 0.71817939 0.71817939 0.71015594\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.68252699 0.69537518 0.69872051\n",
      " 0.73614554 0.71170199 0.7280821  0.72636279 0.72636279 0.71178195\n",
      " 0.68252699 0.69537518 0.69872051 0.73614554 0.71170199 0.7280821\n",
      " 0.72636279 0.72636279 0.71178195        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.68415301 0.70518459 0.70359856 0.72801546 0.70193256 0.72153805\n",
      " 0.72636279 0.72636279 0.71178195 0.68415301 0.70518459 0.70359856\n",
      " 0.72801546 0.70193256 0.72153805 0.72636279 0.72636279 0.71178195]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "best_dataset = 1 # Porque de results, el mayor accuracy en train y test es el de la posición 1\n",
    "\n",
    "hyperparams = {\n",
    " \n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [3, 5, 10, 15, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = DecisionTreeClassifier(random_state = 42)\n",
    "grid = GridSearchCV(model, hyperparams, scoring = \"accuracy\")\n",
    "y_train_fixed = y_train.values.ravel() if hasattr(y_train, \"values\") else y_train\n",
    "grid.fit(TRAIN_DATASETS[best_dataset], y_train_fixed)\n",
    "# Mostrar los mejores parámetros\n",
    "print(\"Mejores parámetros:\", grid.best_params_)\n",
    "print(\"Mejor accuracy:\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.7980\n",
      "Test Accuracy: 0.6818\n"
     ]
    }
   ],
   "source": [
    "# 1️⃣ Obtener el mejor modelo después de GridSearchCV\n",
    "final_model = grid.best_estimator_\n",
    "\n",
    "# 2️⃣ Elegir el dataset óptimo\n",
    "best_dataset = 1\n",
    "X_train_best = TRAIN_DATASETS[best_dataset]\n",
    "X_test_best = TEST_DATASETS[best_dataset]\n",
    "\n",
    "# 3️⃣ Hacer predicciones\n",
    "y_pred_train = final_model.predict(X_train_best)\n",
    "y_pred_test = final_model.predict(X_test_best)\n",
    "\n",
    "# 4️⃣ Evaluar el rendimiento\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6818181818181818\n",
      "Precision: 0.7450980392156863\n",
      "Recall: 0.7676767676767676\n",
      "F1 Score: 0.7562189054726368\n",
      "Confusion Matrix:\n",
      " [[29 26]\n",
      " [23 76]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "# Asumiendo que ya tienes y_test y y_pred (y_prob si calculas ROC AUC)\n",
    "acc = accuracy_score(y_test, y_pred_test)\n",
    "prec = precision_score(y_test, y_pred_test)\n",
    "rec = recall_score(y_test, y_pred_test)\n",
    "f1 = f1_score(y_test, y_pred_test)\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
